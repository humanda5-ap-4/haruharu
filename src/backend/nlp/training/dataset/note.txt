단계	파일명	                    담당	    설명
1	    intent_dataset.json	    정원민	    다양한 의도(label) 포함 문장 수집
2	    train_intent_model.py	소형섭	    Intent 모델 학습, 예측 함수 predict_intent() 제공
3	    tokenizer.py	        소형섭	    단어 토큰화 함수 tokenize() 구현
4	    train_ner_model.py	    소형섭	    BIO 태깅 모델 학습, predict_ner_tags() 구현
5	    index_mapper.py	        소형섭	    토큰 기준으로 start/end 인덱스 반환 함수
6	    nlu_final.py	        소형섭	    전체 흐름 통합, process(text) 완성



6단계 이후 출력 예시
{
  "text": "오늘 볼만한 공연 있어?",
  "intent": "공연",
  "tokens": [
    { "word": "오늘", "tag": "B-DATE", "start": 0, "end": 2 },
    { "word": "볼만한", "tag": "O", "start": 3, "end": 6 },
    { "word": "공연", "tag": "B-EVENT", "start": 7, "end": 9 },
    { "word": "있어", "tag": "O", "start": 10, "end": 12 },
    { "word": "?", "tag": "O", "start": 12, "end": 13 }
  ]
}

2025-05-16
train_ner_model.py 한글까지 완성

2025-05-19
train_ner_model_fallback.py entity_dataset.json을 보고 조사, 어미 제거 "사전에 있는 단어 기준"
index_mapper.py, nlu_final.py
matcher.py, parser.py 완성